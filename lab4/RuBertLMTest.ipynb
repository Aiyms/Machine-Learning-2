{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Сериал очень люблю, но Академия и Земля вызыва...\n",
       "1        думал, что будет лучше идея очень интересна - ...\n",
       "2        с творчеством Головачева я познакомился посред...\n",
       "3        то-то я и в большое неудовольствие прочитал \"А...\n",
       "4        как мне показалось местами сильно смахивает на...\n",
       "                               ...                        \n",
       "19995    Хорошо! Оставляет место для разгадывания загад...\n",
       "19996    Сериал для тех кто в поиске \"квики\" или \"секса...\n",
       "19997    Я вообще-то детективы и боевики люблю, а мелод...\n",
       "19998    Изменить свою жизнь с помощью джакузи.. )) не ...\n",
       "19999    шимпанзе играет в пакмэна!!! и все, больше в э...\n",
       "Name: text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "RUBERT_PATH = 'C:\\\\Users\\Aiym Sergazina\\\\rubert_cased_L-12_H-768_A-12_pt'\n",
    "modelpath = os.path.join(RUBERT_PATH,'pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(os.path.join(RUBERT_PATH,'pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(RUBERT_PATH, do_lower_case=False)\n",
    "config = BertConfig.from_json_file(os.path.join(RUBERT_PATH,'bert_config.json'))\n",
    "model = BertForPreTraining.from_pretrained(modelpath, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_vec(s):\n",
    "    tokenized_text = tokenizer.tokenize(s)\n",
    "    tokenized_text = tokenized_text[:tokenizer.max_model_input_sizes['bert-base-uncased']-2]\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    \n",
    "    segments_ids = [1] * len(tokenized_text)    \n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    predictions = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    sr, sd, td = predictions[0].shape\n",
    "    \n",
    "    vector = []\n",
    "    \n",
    "    for i in range(sd):\n",
    "        currentArr = predictions[0][0][i].detach().numpy()\n",
    "        if len(vector) == 0:\n",
    "            vector = currentArr\n",
    "        else:\n",
    "            vector = np.add(vector, currentArr)\n",
    "    return np.mean(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('Exp_as_vector.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tonality</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-204.517487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-111.591545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-311.379852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-170.935226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-244.520889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tonality      vector\n",
       "0         6 -204.517487\n",
       "1         7 -111.591545\n",
       "2        10 -311.379852\n",
       "3         5 -170.935226\n",
       "4         6 -244.520889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_csv('Exp_as_vector.csv', dtype='float64')\n",
    "vector_means = [exp_vec(s) for s in df['text'].tolist()]\n",
    "dfs['vector'] = vector_means\n",
    "dfs['tonality'] = df['rating']\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dfs['tonality'])\n",
    "y = np.array(dfs['vector']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test  = train_test_split(y, X, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "regressor = RandomForestClassifier(n_estimators=2000, random_state=0)\n",
    "R = regressor.fit(X_train, y_train)\n",
    "y_predict = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[  3   2   3   6   4   2  12  13  27  21]\n",
      " [  1   6   1   4   8   4  15  21  23  28]\n",
      " [  4   3   4   9  14  10  14  34  43  44]\n",
      " [  5   4   9   8  19  11  23  39  68  68]\n",
      " [  2   4  13  15  24  26  49  68  82  99]\n",
      " [  3   7  12  16  19  21  30  71  64  78]\n",
      " [ 12  10  18  19  43  33  60 103 125 137]\n",
      " [ 13  17  24  35  70  58 113 181 252 281]\n",
      " [ 28  24  50  61  72  69 131 233 348 414]\n",
      " [ 42  27  32  73  92  71 163 245 357 524]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.03      0.03      0.03        93\n",
      "           2       0.06      0.05      0.06       111\n",
      "           3       0.02      0.02      0.02       179\n",
      "           4       0.03      0.03      0.03       254\n",
      "           5       0.07      0.06      0.06       382\n",
      "           6       0.07      0.07      0.07       321\n",
      "           7       0.10      0.11      0.10       560\n",
      "           8       0.18      0.17      0.18      1044\n",
      "           9       0.25      0.24      0.25      1430\n",
      "          10       0.31      0.32      0.32      1626\n",
      "\n",
      "    accuracy                           0.20      6000\n",
      "   macro avg       0.11      0.11      0.11      6000\n",
      "weighted avg       0.20      0.20      0.20      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(y_test, y_predict) \n",
    "print('Confusion Matrix :')\n",
    "print(results)\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict, test):\n",
    "    errors = abs(predict - test)\n",
    "    accuracy = 100 - np.mean(100 * (errors / test))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.63564814814815"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_predict, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
